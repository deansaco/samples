{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Web Research Agent with Tavily üåê üü†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome! In this tutorial, you'll learn how to build a web research agent that can search, extract, crawl, and reason over live web data.\n",
    "\n",
    "These skills are essential for anyone building AI agents or applications that need up-to-date, relevant information from the internet. By learning how to programmatically access and process real-time web data, you'll be able to bridge the gap between static language models and the dynamic world they operate in, making your agents smarter, more accurate, and context-aware.\n",
    "\n",
    "The AWS Strands Agent Framework enables rapid development of  AI agents with minimal code. Many research agent implementations require extensive development efforts and rely on deterministic logic with constrained inputs and outputs. Alternatively, Strands facilitates building highly dynamic agents through natural language. Strands agents leverage prompt engineering to dynamically generate varied output types and accept diverse natural language inputs seamlessly.\n",
    "\n",
    "The core philosophy of Strands shifts complexity from hard-coded logic directly into the weights of the LLM, granting the model significant autonomy to determine agent behavior. This design approach ensures agents remain highly flexible and scalable, easily benefiting from advancements in new model releases. By simply integrating updated LLMs, developers can immediately unlock significant performance improvements without needing to modify any existing agent logic.\n",
    "\n",
    "By the end of this lesson, you'll know how to:\n",
    "- Connect agents to the web for up-to-date research\n",
    "- Orchestrate the web tools dynamically with the Strands agent framework\n",
    "- Build dynamic research agents capable of performing a range of tasks, including deep research, report writing, direct question answering, list building, etc.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Follow these steps to set up:\n",
    "\n",
    "1. **Sign up** for Tavily at [app.tavily.com](https://app.tavily.com/home/) to get your API key.\n",
    "\n",
    "   *Refer to the screenshots linked below for step-by-step guidance:*\n",
    "\n",
    "   - [Screenshot: Signup Page](assets/sign-up.png)\n",
    "   - [Screenshot: Tavily API Keys Dashboard](assets/api-key.png)\n",
    "\n",
    "\n",
    "2. **Copy your API key** from your Tavily account dashboard.\n",
    "\n",
    "3. **Paste your API key** into the cell below and execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To export your API key into a .env file, run the following cell (replace with your actual keys):\n",
    "!echo \"TAVILY_API_KEY=<your-tavily-api-key>\" >> .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and import necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install strands-agents tavily-python --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Your Tavily API Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will instantiate the Tavily client with your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Prompt the user to securely input the API key if not already set in the environment\n",
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY:\\n\")\n",
    "\n",
    "# Initialize the Tavily API client using the loaded or provided API key\n",
    "tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **‚ÑπÔ∏è Strands Agent Architecture**\n",
    ">\n",
    "> This research agent is composed of three primary components:\n",
    ">\n",
    "> 1. **Language Model:** Acts as the agent's \"brain,\" responsible for understanding queries and generating responses.\n",
    "> 2. **Tools:** Includes `web search` and `web crawl` functionalities, enabling the agent to interact with and gather information from the internet. Also includes a `research formatting` tool to allow the agent to dynamically alter the research output format based on the user's intent.\n",
    "> 3. **System Prompt:** Guides the agent's behavior, outlining how and when to use each tool to achieve its research objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Language Model\n",
    "\n",
    "We'll use the Strands SDK to set up a language model for our agent via AWS Bedrock. In this example, we're choosing Anthropic's Claude 3.7 Sonnet model, but you can substitute any [Bedrock-supported model](https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html) as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands.models import BedrockModel\n",
    "\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "    region_name=\"us-east-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tool Definitions \n",
    "Let's define the following modular tools with the Tavily-LangChain integration:\n",
    "1. **Search** the web for relevant information\n",
    "\n",
    "2. **Crawl** entire websites and scrape their content\n",
    "\n",
    "3. **Format Responses** dynamically using an LLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Tavily Search Tool üîç\n",
    "\n",
    "We'll wrap the Tavily search endpoint in the Strands `@tool` decorator. Tools are passed to agents during initialization or at runtime, making them available for use throughout the agent's lifecycle. We implement a `format_search_results_for_agent` helper function which parses Tavily search results into a clear, structured format that's easy for the LLM to process. \n",
    "\n",
    "The agent will have the ability to set the query, time range, and include domains parameters. Feel free to experiment with different Tavily API parameter configurations to see Tavily in action. You can adjust parameters such as the number of results, time range, and domain filters to tailor your search. For more information, read the search [API reference](https://docs.tavily.com/documentation/api-reference/endpoint/search) and [best practices guide](https://docs.tavily.com/documentation/best-practices/best-practices-search). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent, tool\n",
    "\n",
    "def format_search_results_for_agent(tavily_result):\n",
    "    \"\"\"\n",
    "    Format Tavily search results into a well-structured string for language models.\n",
    "\n",
    "    Args:\n",
    "        tavily_result (Dict): A Tavily search result dictionary\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string with search results organized for easy consumption by LLMs\n",
    "    \"\"\"\n",
    "    if (\n",
    "        not tavily_result\n",
    "        or \"results\" not in tavily_result\n",
    "        or not tavily_result[\"results\"]\n",
    "    ):\n",
    "        return \"No search results found.\"\n",
    "\n",
    "    formatted_results = []\n",
    "\n",
    "    for i, doc in enumerate(tavily_result[\"results\"], 1):\n",
    "        # Extract metadata\n",
    "        title = doc.get(\"title\", \"No title\")\n",
    "        url = doc.get(\"url\", \"No URL\")\n",
    "\n",
    "        # Create a formatted entry\n",
    "        formatted_doc = f\"\\nRESULT {i}:\\n\"\n",
    "        formatted_doc += f\"Title: {title}\\n\"\n",
    "        formatted_doc += f\"URL: {url}\\n\"\n",
    "\n",
    "        raw_content = doc.get(\"raw_content\")\n",
    "\n",
    "        # Prefer raw_content if it's available and not just whitespace\n",
    "        if raw_content and raw_content.strip():\n",
    "            formatted_doc += f\"Raw Content: {raw_content.strip()}\\n\"\n",
    "        else:\n",
    "            # Fallback to content if raw_content is not suitable or not available\n",
    "            content = doc.get(\"content\", \"\").strip()\n",
    "            formatted_doc += f\"Content: {content}\\n\"\n",
    "\n",
    "        formatted_results.append(formatted_doc)\n",
    "\n",
    "    # Join all formatted results with a separator\n",
    "    return \"\\n\" + \"\\n\".join(formatted_results)\n",
    "\n",
    "@tool\n",
    "def tavily_search(\n",
    "    query: str, time_range: str | None = None, include_domains: str | None = None\n",
    ") -> str:\n",
    "    \"\"\"Perform a web search using Tavily API. Returns the search results as a string, with the title, url, and content of each result ranked by relevance.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query to be sent for the web search.\n",
    "        time_range (str | None, optional): Limits results to content published within a specific timeframe.\n",
    "            Valid values: 'd' (day - 24h), 'w' (week - 7d), 'm' (month - 30d), 'y' (year - 365d).\n",
    "            Defaults to None.\n",
    "        include_domains (list[str] | None, optional): A list of domains to restrict search results to.\n",
    "            Only results from these domains will be returned. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        formatted_results (str): The web search results\n",
    "    \"\"\"\n",
    "    client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "    formatted_results = format_search_results_for_agent(\n",
    "        client.search(\n",
    "            query=query,\n",
    "            max_results=5,\n",
    "            time_range=time_range,\n",
    "            include_domains=include_domains,\n",
    "        )\n",
    "    )\n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Tavily Crawl Tool üï∏Ô∏è \n",
    "\n",
    "Now let‚Äôs use Tavily to crawl a webpage and extract all its links. Web crawling is the process of automatically navigating through websites by following hyperlinks to discover numerous web pages and URLs (think of it like falling down a Wikipedia rabbit hole üêá‚Äîclicking from page to page, diving deeper into interconnected topics). For autonomous web agents, this capability is essential for accessing deep web data which might be difficult to retrieve via search. \n",
    "\n",
    "\n",
    "We'll wrap the Tavily crawl endpoint in the Strands `@tool` decorator, similar to the search tool. We implement a `format_crawl_results_for_agent` helper function which parses Tavily search results into a clear, structured format that's easy for the LLM to process. \n",
    "\n",
    "The agent will have the ability to set the crawled url and the crawl instruction. You can adjust parameters such as the crawl depth, limit, and domain filters to tailor your crawl. For more information, read the crawl [API reference](https://docs.tavily.com/documentation/api-reference/endpoint/crawl) and [best practices guide](https://docs.tavily.com/documentation/best-practices/best-practices-crawl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_crawl_results_for_agent(tavily_result):\n",
    "    \"\"\"\n",
    "    Format Tavily crawl results into a well-structured string for language models.\n",
    "\n",
    "    Args:\n",
    "        tavily_result (List[Dict]): A list of Tavily crawl result dictionaries\n",
    "\n",
    "    Returns:\n",
    "        formatted_results (str): The formatted crawl results\n",
    "    \"\"\"\n",
    "    if not tavily_result:\n",
    "        return \"No crawl results found.\"\n",
    "\n",
    "    formatted_results = []\n",
    "\n",
    "    for i, doc in enumerate(tavily_result, 1):\n",
    "        # Extract metadata\n",
    "        url = doc.get(\"url\", \"No URL\")\n",
    "        raw_content = doc.get(\"raw_content\", \"\")\n",
    "\n",
    "        # Create a formatted entry\n",
    "        formatted_doc = f\"\\nRESULT {i}:\\n\"\n",
    "        formatted_doc += f\"URL: {url}\\n\"\n",
    "\n",
    "        if raw_content:\n",
    "            # Extract a title from the first line if available\n",
    "            title_line = raw_content.split(\"\\n\")[0] if raw_content else \"No title\"\n",
    "            formatted_doc += f\"Title: {title_line}\\n\"\n",
    "            formatted_doc += (\n",
    "                f\"Content: {raw_content[:4000]}...\\n\"\n",
    "                if len(raw_content) > 4000\n",
    "                else f\"Content: {raw_content}\\n\"\n",
    "            )\n",
    "\n",
    "        formatted_results.append(formatted_doc)\n",
    "\n",
    "    # Join all formatted results with a separator\n",
    "    return \"\\n\" + \"-\" * 40 + \"\\n\".join(formatted_results)\n",
    "\n",
    "\n",
    "@tool\n",
    "def tavily_crawl(\n",
    "    url: str, max_depth: int = 2, limit: int = 20, instructions: str | None = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Crawls a given URL using the Tavily API, processes the results, and formats them\n",
    "    into a string suitable for consumption by a large language model (LLM).\n",
    "\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the website to crawl.\n",
    "\n",
    "        instructions (str | None, optional): Specific instructions to guide the\n",
    "                                             Tavily crawler, such as focusing on\n",
    "                                             certain types of content or avoiding\n",
    "                                             others. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the crawl results. Each result includes\n",
    "             the URL and a snippet of the page content.\n",
    "             If an error occurs during the crawl process (e.g., network issue,\n",
    "             API error), a string detailing the error and the attempted URL is\n",
    "             returned.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if url.strip().startswith(\"{\") and '\"url\":' in url:\n",
    "        import re\n",
    "\n",
    "        m = re.search(r'\"url\"\\s*:\\s*\"([^\"]+)\"', url)\n",
    "        if m:\n",
    "            url = m.group(1)\n",
    "\n",
    "    if not url.startswith((\"http://\", \"https://\")):\n",
    "        url = \"https://\" + url\n",
    "\n",
    "    try:\n",
    "        api_response = tavily_client.crawl(\n",
    "            url=url,\n",
    "            max_depth=max_depth,\n",
    "            limit=limit,\n",
    "            instructions=instructions,\n",
    "        )\n",
    "\n",
    "        tavily_results = (\n",
    "            api_response.get(\"results\")\n",
    "            if isinstance(api_response, dict)\n",
    "            else api_response\n",
    "        )\n",
    "\n",
    "        formatted = format_crawl_results_for_agent(tavily_results)\n",
    "        return formatted\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\\n\" f\"URL attempted: {url}\\n\" \"Failed to crawl the website.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Research Formatter Tool\n",
    "\n",
    "The `format_research_response` tool uses a specialized agent to transform raw research content into clear, well-structured, and properly cited responses. It ensures every factual claim is supported by inline citations and provides a complete \"Sources\" section with URLs. The tool automatically selects the most appropriate format‚Äîsuch as direct answer, blog, academic report, executive summary, bullet points, or comparison‚Äîbased on the user's question and the research content.\n",
    "\n",
    "Use this tool as the final step, after completing all research, to transform your findings into a clear, well-structured, and audience-appropriate response before delivering it to the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define specialized system prompt for research response formatting\n",
    "RESEARCH_FORMATTER_PROMPT = \"\"\"\n",
    "You are a specialized Research Response Formatter Agent. Your role is to transform research content into well-structured, properly cited, and reader-friendly formats.\n",
    "\n",
    "Core formatting requirements (ALWAYS apply):\n",
    "1. Include inline citations using [n] notation for EVERY factual claim\n",
    "2. Provide a complete \"Sources\" section at the end with numbered references an urls\n",
    "3. Write concisely - no repetition or filler words\n",
    "4. Ensure information density - every sentence should add value\n",
    "5. Maintain professional, objective tone\n",
    "6. Format your response in markdown\n",
    "\n",
    "Based on the semantics of the user's original research question, format your response in one of the following styles:\n",
    "- **Direct Answer**: Concise, focused response that directly addresses the question\n",
    "- **Blog Style**: Engaging introduction, subheadings, conversational tone, conclusion\n",
    "- **Academic Report**: Abstract, methodology, findings, analysis, conclusions, references\n",
    "- **Executive Summary**: Key findings upfront, bullet points, actionable insights\n",
    "- **Bullet Points**: Structured lists with clear hierarchy and supporting details\n",
    "- **Comparison**: Side-by-side analysis with clear criteria and conclusions\n",
    "\n",
    "When format is not specified, analyze the research content and user query to determine:\n",
    "- Complexity level (simple vs. comprehensive)\n",
    "- Audience (general public vs. technical)\n",
    "- Purpose (informational vs. decision-making)\n",
    "- Content type (factual summary vs. analytical comparison)\n",
    "\n",
    "Your response below should be polished, containing only the information that is relevant to the user's query and NOTHING ELSE.\n",
    "\n",
    "Your final research response:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def format_research_response(\n",
    "    research_content: str, format_style: str = None, user_query: str = None\n",
    ") -> str:\n",
    "    \"\"\"Format research content into a well-structured, properly cited response.\n",
    "\n",
    "    This tool uses a specialized Research Formatter Agent to transform raw research\n",
    "    into polished, reader-friendly content with proper citations and optimal structure.\n",
    "\n",
    "    Args:\n",
    "        research_content (str): The raw research content to be formatted\n",
    "        format_style (str, optional): Desired format style (e.g., \"blog\", \"report\",\n",
    "                                    \"executive summary\", \"bullet points\", \"direct answer\")\n",
    "        user_query (str, optional): Original user question to help determine appropriate format\n",
    "\n",
    "    Returns:\n",
    "        str: Professionally formatted research response with proper citations,\n",
    "             clear structure, and appropriate style for the intended audience\n",
    "    \"\"\"\n",
    "    try:\n",
    "        bedrock_model = BedrockModel(\n",
    "            model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "            region_name=\"us-east-1\",\n",
    "        )\n",
    "        # Strands Agents SDK makes it easy to create a specialized agent\n",
    "        formatter_agent = Agent(\n",
    "            model=bedrock_model,\n",
    "            system_prompt=RESEARCH_FORMATTER_PROMPT,\n",
    "        )\n",
    "\n",
    "        # Prepare the input for the formatter\n",
    "        format_input = f\"Research Content:\\n{research_content}\\n\\n\"\n",
    "\n",
    "        if format_style:\n",
    "            format_input += f\"Requested Format Style: {format_style}\\n\\n\"\n",
    "\n",
    "        if user_query:\n",
    "            format_input += f\"Original User Query: {user_query}\\n\\n\"\n",
    "\n",
    "        format_input += \"Please format this research content according to the guidelines and appropriate style.\"\n",
    "\n",
    "        # Call the agent and return its response\n",
    "        response = formatter_agent(format_input)\n",
    "        return str(response)\n",
    "    except Exception as e:\n",
    "        return f\"Error in research formatting: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Agent System Prompt\n",
    "\n",
    "The Strands SDK enables the agent to reason about which actions to take, use the available tools in sequence, and iterate as needed until it completes its research task. The system prompt is especially important‚Äîit instructs the agent on best practices for using the tools together, ensuring that the agent's responses are thorough, accurate, and well-sourced.\n",
    "\n",
    "You are encouraged to experiment with the system prompt or try different language models to change the agent's style, personality, or optimize its performance for specific use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert research assistant specializing in deep, comprehensive information gathering and analysis.\n",
    "\n",
    "Your TOOLS include:\n",
    "\n",
    "1. WEB SEARCH\n",
    "- Conduct thorough web searches using the tavily_search tool.\n",
    "- You will enter a search query and the tavily_search tool will return 10 web searchresults ranked by semantic relevance.\n",
    "- Your search results will include the title, url, and content of 10 results ranked by semantic relevance.\n",
    "\n",
    "2. WEB CRAWL\n",
    "- Conduct deep web crawls with the tavily_crawl tool.\n",
    "- You will enter a url and the tavily_crawl tool will find all the nested links.\n",
    "- Your crawl results will include the url and content of the pages that were discovered.\n",
    "- This tool is great for finding all the information that is linked from a single page.\n",
    "\n",
    "3. FORMATTING RESEARCH RESPONSE\n",
    "- You will use the format_research_response tool to format your research response.\n",
    "- This tool will create a well-structured response that is easy to read and understand.\n",
    "- The response will clearly address the user's query, the research results.\n",
    "- The response will be in markdown format.\n",
    "\n",
    "RULES:\n",
    "- You must start the research process by creating a plan. Think step by step about what you need to do to answer the research question.\n",
    "- You must use the format_research_response tool to format your research response before returning a response.\n",
    "- You can iterate on your research plan and research response multiple times, using combinations of the tools available to you until you are satisfied with the results.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine the search and crawl tools into a single agent, as shown in the diagram below.\n",
    "\n",
    "<div align=\"left\">\n",
    "  <img src=\"assets/agent.svg\" alt=\"agent\", width = 500/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[\n",
    "        tavily_search,\n",
    "        tavily_crawl,\n",
    "        format_research_response,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_prompt = \"crawl tavily.com, identify all their integrations, and then find relevant news articles/social media posts about the integrations if available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research = web_agent(research_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the tool execution order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_used = []\n",
    "\n",
    "print(\"üöÄ Tool Execution Flow\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "\n",
    "for i, msg in enumerate(web_agent.messages):\n",
    "    if msg.get(\"role\") == \"assistant\" and msg.get(\"content\"):\n",
    "        content = msg.get(\"content\", [])\n",
    "        \n",
    "        for item in content:\n",
    "            if isinstance(item, dict) and 'toolUse' in item:\n",
    "                tool_use = item['toolUse']\n",
    "                tool_name = tool_use.get('name', 'unknown')\n",
    "                tool_input = tool_use.get('input', {})\n",
    "                tools_used.append(tool_name)\n",
    "                \n",
    "                # Choose emoji based on tool type\n",
    "                if 'crawl' in tool_name:\n",
    "                    emoji = 'üï∑Ô∏è'\n",
    "                elif 'search' in tool_name:\n",
    "                    emoji = 'üîç'\n",
    "                elif 'format' in tool_name:\n",
    "                    emoji = 'üìù'\n",
    "                else:\n",
    "                    emoji = '‚ö°'\n",
    "                \n",
    "                print(f\"{len(tools_used):2d}. {emoji} {tool_name}\")\n",
    "                \n",
    "                # Format input nicely\n",
    "                if isinstance(tool_input, dict):\n",
    "                    for key, value in tool_input.items():\n",
    "                        # Truncate long values for readability\n",
    "                        if isinstance(value, str) and len(value) > 80:\n",
    "                            value = value[:77] + \"...\"\n",
    "                        print(f\"    üí≠ {key}: {value}\")\n",
    "                else:\n",
    "                    print(f\"    üí≠ input: {tool_input}\")\n",
    "                print()  # Add blank line for readability\n",
    "\n",
    "print(f\"üéØ Completed {len(tools_used)} tool invocations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets view the final research output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(research.message[\"content\"][0][\"text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the agent sub steps for monitoring and observability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_agent.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research.metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
