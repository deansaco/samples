{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lambda Error Analysis with Strands Agents\n",
        "\n",
        "This notebook demonstrates how to deploy and use an AI-powered error analysis system for AWS Lambda functions. The system automatically analyzes Lambda failures using Strands Agents and Amazon Bedrock to provide intelligent root cause analysis and actionable recommendations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What This System Does\n",
        "\n",
        "When a Lambda function fails, instead of getting generic error messages like:\n",
        "```\n",
        "AttributeError: 'NoneType' object has no attribute 'lower'\n",
        "```\n",
        "\n",
        "You get intelligent analysis like:\n",
        "```\n",
        "Root Cause: Missing null check on 'email' field before calling .lower() method.\n",
        "The user_data dictionary contains email=None, causing AttributeError when attempting\n",
        "string operations.\n",
        "\n",
        "Recommendation: Add null validation before processing:\n",
        "  if user_data.get('email'):\n",
        "      email = user_data['email'].lower().strip()\n",
        "  else:\n",
        "      raise ValueError('Email is required')\n",
        "\n",
        "Confidence: 0.92 (Very High)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "Before starting, ensure you have:\n",
        "\n",
        "1. **AWS Account** with appropriate permissions\n",
        "2. **AWS CLI** installed and configured\n",
        "3. **Node.js** 18+ and npm\n",
        "4. **Python** 3.12+\n",
        "5. **Docker** installed and running (for building Lambda layers)\n",
        "6. **AWS CDK** installed globally: `npm install -g aws-cdk`\n",
        "7. **Bedrock Model Access** - Ensure Claude Sonnet models are enabled in your AWS account"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project Structure\n",
        "\n",
        "```\n",
        "lambda-error-analysis/\n",
        "‚îú‚îÄ‚îÄ cdk/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ lambda/\n",
        "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sample-business-function/    # Demo Lambda with @decorator\n",
        "‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lambda_function.py       # User data processing function\n",
        "‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ decorator.py             # @error_capture decorator\n",
        "‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test-events.json         # Test payloads\n",
        "‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md                # Function documentation\n",
        "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ error-analyzer-agent/        # AI-powered error analyzer\n",
        "‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ lambda_function.py       # Main handler\n",
        "‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ agent.py                 # Strands Agent with 3 tools\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ layers/\n",
        "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ strands-layer/               # Strands SDK dependencies\n",
        "‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ build.sh                 # Layer build script\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ stacks/\n",
        "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lambda-error-analysis-stack.ts  # CDK infrastructure\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ constant.ts                      # Project constants\n",
        "‚îú‚îÄ‚îÄ knowledge_base/                      # AI knowledge base content\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ lambda-error-patterns.md         # Common Lambda failures\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ aws-service-errors.md            # AWS error codes reference\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ troubleshooting-guide.md         # Debugging methodology\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ best-practices.md                # Lambda best practices\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ common-errors.md                 # Common error solutions\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ README.md                        # Knowledge base docs\n",
        "‚îú‚îÄ‚îÄ images/                            # Architecture diagrams\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ generate_diagram.py              # Diagram generation script\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                 # Diagram dependencies\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ lambda-error-analysis-architecture.png\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ lambda-error-analysis-architecture-transparent.png\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ README.md                        # Diagram documentation\n",
        "‚îú‚îÄ‚îÄ cdk-app.ts                           # CDK app entry point\n",
        "‚îú‚îÄ‚îÄ cdk.json                             # CDK configuration\n",
        "‚îú‚îÄ‚îÄ package.json                         # NPM dependencies\n",
        "‚îú‚îÄ‚îÄ tsconfig.json                        # TypeScript config\n",
        "‚îî‚îÄ‚îÄ deploy-agent.ipynb                   # This deployment notebook\n",
        "‚îî‚îÄ‚îÄ README.md                            # Comprehensive documentation\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "### Step 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install CDK dependencies\n",
        "!npm install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Python dependencies\n",
        "!pip install pandas boto3 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Verify Docker is Running\n",
        "\n",
        "Docker is required for:\n",
        "- Building the Strands Lambda layer\n",
        "- Knowledge Base custom resource Lambda\n",
        "\n",
        "Let's check if Docker is running before proceeding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def check_docker():\n",
        "    \"\"\"Check if Docker daemon is running\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            ['docker', 'info'],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=5\n",
        "        )\n",
        "        if result.returncode == 0:\n",
        "            print(\"‚úÖ Docker is running\")\n",
        "            # Get Docker version\n",
        "            version_result = subprocess.run(\n",
        "                ['docker', '--version'],\n",
        "                capture_output=True,\n",
        "                text=True\n",
        "            )\n",
        "            print(f\"   {version_result.stdout.strip()}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"‚ùå Docker is not running\")\n",
        "            print(\"\\n‚ö†Ô∏è  Please start Docker Desktop and wait for it to fully start.\")\n",
        "            print(\"   Then run this cell again.\")\n",
        "            return False\n",
        "    except FileNotFoundError:\n",
        "        print(\"‚ùå Docker is not installed\")\n",
        "        print(\"\\n‚ö†Ô∏è  Please install Docker Desktop from: https://www.docker.com/products/docker-desktop\")\n",
        "        return False\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"‚ùå Docker command timed out\")\n",
        "        print(\"\\n‚ö†Ô∏è  Docker might be starting. Please wait and try again.\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error checking Docker: {e}\")\n",
        "        return False\n",
        "\n",
        "docker_running = check_docker()\n",
        "\n",
        "if not docker_running:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚õî STOP: Docker must be running before continuing\")\n",
        "    print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Verify AWS Credentials\n",
        "\n",
        "Check if AWS credentials are configured and accessible:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import boto3\n",
        "\n",
        "# Check if AWS credentials are available\n",
        "try:\n",
        "    sts = boto3.client('sts')\n",
        "    identity = sts.get_caller_identity()\n",
        "    session = boto3.Session()\n",
        "    \n",
        "    # Export environment variables for CDK\n",
        "    os.environ['CDK_DEFAULT_ACCOUNT'] = identity['Account']\n",
        "    os.environ['CDK_DEFAULT_REGION'] = session.region_name\n",
        "    \n",
        "    print(f\"‚úÖ AWS credentials detected!\")\n",
        "    print(f\"   Account: {identity['Account']}\")\n",
        "    print(f\"   Region: {session.region_name}\")\n",
        "    print(f\"\\n‚úÖ Environment variables set for CDK:\")\n",
        "    print(f\"   CDK_DEFAULT_ACCOUNT={identity['Account']}\")\n",
        "    print(f\"   CDK_DEFAULT_REGION={session.region_name}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå AWS credentials not found: {e}\")\n",
        "    print(f\"\\n‚ö†Ô∏è  Please configure AWS credentials before continuing.\")\n",
        "    print(f\"   See: https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Bootstrap CDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bootstrap CDK (if not done already)\n",
        "!npx cdk bootstrap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Architecture\n",
        "\n",
        "![Lambda Error Analysis Architecture](images/lambda-error-analysis-architecture.png)\n",
        "\n",
        "### Components:\n",
        "\n",
        "1. **Sample Business Function** - Lambda with @error_capture decorator that captures failures\n",
        "2. **EventBridge** - Routes failure events to the analyzer\n",
        "3. **Error Analyzer Agent** - AI-powered analysis using Strands SDK\n",
        "4. **Bedrock Knowledge Base** - Searchable documentation and error patterns\n",
        "5. **DynamoDB** - Stores analysis results with confidence scoring\n",
        "6. **S3** - Source code storage for analysis\n",
        "\n",
        "### Data Flow:\n",
        "\n",
        "1. Lambda function fails ‚Üí @decorator captures exception\n",
        "2. EventBridge routes failure event to Error Analyzer\n",
        "3. Agent uses 3 tools to gather context:\n",
        "   - `fetch_source_code()` - Gets Lambda source from S3\n",
        "   - `fetch_cloudwatch_logs()` - Retrieves execution logs\n",
        "   - `search_knowledge_base()` - Queries documentation\n",
        "4. Claude Sonnet analyzes with confidence scoring\n",
        "5. Enhanced analysis stored in DynamoDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Code Walkthrough\n",
        "\n",
        "### 1. Sample Business Function\n",
        "\n",
        "Simulates a digital banking user registration service that validates customer data, enriches profiles, and assigns membership tiers. Contains 8 intentional bugs (missing fields, null handling, type conversions, edge cases) that represent common validation scenarios developers face during development."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View the sample business function\n",
        "with open('cdk/lambda/sample-business-function/lambda_function.py', 'r') as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Points:**\n",
        "- Processes user registration data\n",
        "- Validates, enriches, and calculates user tier\n",
        "- Contains realistic bugs: missing null checks, type errors, division by zero\n",
        "- Uses `@error_capture` decorator to capture failures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. The @error_capture Decorator\n",
        "\n",
        "This decorator automatically captures exceptions and publishes events to EventBridge:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View the decorator (key sections)\n",
        "print(\"\"\"\n",
        "The @error_capture decorator:\n",
        "\n",
        "1. Wraps your Lambda handler\n",
        "2. Captures exceptions with full stack traces\n",
        "3. Publishes events to EventBridge:\n",
        "   - TaskSucceeded (statusCode 200-299)\n",
        "   - TaskFailed (exceptions or statusCode >= 400)\n",
        "   - TaskUpdate (statusCode 102)\n",
        "\n",
        "4. Includes Lambda execution context:\n",
        "   - Request ID\n",
        "   - Function name\n",
        "   - CloudWatch log group/stream\n",
        "\n",
        "Usage:\n",
        "  @error_capture(logger, eventbridge, event_bus_name, True, True, True)\n",
        "  def lambda_handler(event, context):\n",
        "      # Your business logic\n",
        "      return {\"statusCode\": 200}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Error Analyzer Agent\n",
        "\n",
        "The heart of the system - an AI agent with 3 specialized tools:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View the agent code (key sections)\n",
        "with open('cdk/lambda/error-analyzer-agent/agent.py', 'r') as f:\n",
        "    content = f.read()\n",
        "    # Show the tool definitions\n",
        "    print(\"=\" * 80)\n",
        "    print(\"TOOL 1: fetch_source_code()\")\n",
        "    print(\"=\" * 80)\n",
        "    start = content.find('@tool\\ndef fetch_source_code')\n",
        "    end = content.find('\\n\\n@tool', start + 1)\n",
        "    print(content[start:end])\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TOOL 2: fetch_cloudwatch_logs()\")\n",
        "    print(\"=\" * 80)\n",
        "    start = content.find('@tool\\ndef fetch_cloudwatch_logs')\n",
        "    end = content.find('\\n\\n@tool', start + 1)\n",
        "    print(content[start:end])\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TOOL 3: search_knowledge_base()\")\n",
        "    print(\"=\" * 80)\n",
        "    start = content.find('@tool\\ndef search_knowledge_base')\n",
        "    end = content.find('\\n\\ndef analyze_error', start)\n",
        "    print(content[start:end])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Agent Capabilities:**\n",
        "\n",
        "1. **fetch_source_code()** - Retrieves Lambda source code from S3 for analysis\n",
        "2. **fetch_cloudwatch_logs()** - Gets execution logs filtered by request ID\n",
        "3. **search_knowledge_base()** - Queries Bedrock Knowledge Base for error patterns\n",
        "\n",
        "The agent uses Claude Sonnet with extended thinking to:\n",
        "- Analyze error context from all three sources\n",
        "- Identify root cause with evidence\n",
        "- Provide specific, actionable recommendations\n",
        "- Calculate confidence score based on available evidence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy the Stack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build TypeScript and Lambda layer\n",
        "!npm run deploy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This will:\n",
        "1. Build TypeScript CDK code\n",
        "2. Build Strands Lambda layer using Docker\n",
        "3. Deploy all AWS resources:\n",
        "   - 2 Lambda functions\n",
        "   - EventBridge rule\n",
        "   - S3 bucket with source code and knowledge base\n",
        "   - DynamoDB table for analysis results\n",
        "   - Bedrock Knowledge Base\n",
        "   - IAM roles and permissions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sync Knowledge Base with Latest Documentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import boto3\n",
        "import time\n",
        "\n",
        "# Initialize clients\n",
        "bedrock_agent = boto3.client('bedrock-agent')\n",
        "cfn_client = boto3.client('cloudformation')\n",
        "\n",
        "# Get stack outputs\n",
        "stack_name = 'LambdaErrorAnalysisStack'\n",
        "try:\n",
        "    response = cfn_client.describe_stacks(StackName=stack_name)\n",
        "    outputs = response['Stacks'][0]['Outputs']\n",
        "    \n",
        "    # Extract Knowledge Base ID and Data Source ID from outputs\n",
        "    kb_id = next(o['OutputValue'] for o in outputs if o['OutputKey'] == 'KnowledgeBaseId')\n",
        "    ds_id = next(o['OutputValue'] for o in outputs if o['OutputKey'] == 'DataSourceId')\n",
        "    \n",
        "    print(f\"üìö Knowledge Base ID: {kb_id}\")\n",
        "    print(f\"üìÅ Data Source ID: {ds_id}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error getting stack outputs: {e}\")\n",
        "    raise\n",
        "\n",
        "# Start ingestion job\n",
        "print(f\"\\nüöÄ Starting ingestion job...\")\n",
        "try:\n",
        "    response = bedrock_agent.start_ingestion_job(\n",
        "        knowledgeBaseId=kb_id,\n",
        "        dataSourceId=ds_id,\n",
        "        description=\"Sync Lambda source code after deployment\"\n",
        "    )\n",
        "    \n",
        "    ingestion_job_id = response['ingestionJob']['ingestionJobId']\n",
        "    print(f\"‚úÖ Job ID: {ingestion_job_id}\")\n",
        "    print(f\"   Status: {response['ingestionJob']['status']}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error starting ingestion: {e}\")\n",
        "    raise\n",
        "\n",
        "# Monitor progress\n",
        "print(\"\\n‚è≥ Monitoring ingestion progress...\")\n",
        "dots = \"\"\n",
        "while True:\n",
        "    status_response = bedrock_agent.get_ingestion_job(\n",
        "        knowledgeBaseId=kb_id,\n",
        "        dataSourceId=ds_id,\n",
        "        ingestionJobId=ingestion_job_id\n",
        "    )\n",
        "    \n",
        "    status = status_response['ingestionJob']['status']\n",
        "    \n",
        "    # Progress indicator\n",
        "    dots += \".\"\n",
        "    if len(dots) > 50:\n",
        "        dots = \".\"\n",
        "    print(f\"\\rStatus: {status} {dots}\", end=\"\", flush=True)\n",
        "    \n",
        "    if status in ['COMPLETE', 'FAILED', 'STOPPED']:\n",
        "        print()  # New line\n",
        "        break\n",
        "    \n",
        "    time.sleep(10)\n",
        "\n",
        "# Print results\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "if status == 'COMPLETE':\n",
        "    stats = status_response['ingestionJob'].get('statistics', {})\n",
        "    print(\"‚úÖ INGESTION COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"üìÑ Documents Scanned:    {stats.get('numberOfDocumentsScanned', 0)}\")\n",
        "    print(f\"‚ú® Documents Indexed:    {stats.get('numberOfNewDocumentsIndexed', 0)}\")\n",
        "    print(f\"üîÑ Documents Modified:   {stats.get('numberOfModifiedDocumentsIndexed', 0)}\")\n",
        "    print(f\"üóëÔ∏è  Documents Deleted:    {stats.get('numberOfDocumentsDeleted', 0)}\")\n",
        "    print(f\"‚ùå Documents Failed:     {stats.get('numberOfDocumentsFailed', 0)}\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nüéâ Knowledge Base is ready for error analysis!\")\n",
        "else:\n",
        "    print(f\"‚ùå INGESTION FAILED: {status}\")\n",
        "    print(\"=\"*70)\n",
        "    if 'failureReasons' in status_response['ingestionJob']:\n",
        "        print(\"Failure Reasons:\")\n",
        "        for reason in status_response['ingestionJob']['failureReasons']:\n",
        "            print(f\"  - {reason}\")\n",
        "    print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discover Deployed Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get deployed function names\n",
        "import boto3\n",
        "import json\n",
        "\n",
        "lambda_client = boto3.client('lambda')\n",
        "region = boto3.session.Session().region_name\n",
        "\n",
        "# List our functions (filter out CDK helpers)\n",
        "functions = lambda_client.list_functions()\n",
        "helpers = ['LogRetention', 'OpenSearchIndexCRProvider', 'CustomS3AutoDeleteObjects', 'CustomCDKBucketDeployment']\n",
        "our_functions = [f for f in functions['Functions'] \n",
        "                 if 'LambdaErrorAnalysis' in f['FunctionName'] \n",
        "                 and not any(h in f['FunctionName'] for h in helpers)]\n",
        "\n",
        "print(\"‚úÖ Deployed Lambda Functions:\")\n",
        "for func in our_functions:\n",
        "    print(f\"   ‚Ä¢ {func['FunctionName']}\")\n",
        "    if 'sample-business' in func['FunctionName']:\n",
        "        business_function_name = func['FunctionName']\n",
        "    elif 'error-analyzer' in func['FunctionName']:\n",
        "        analyzer_function_name = func['FunctionName']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions for Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def extract_execution_logs(all_events: list, request_id: str) -> list:\n",
        "    \"\"\"Extract all logs between START and REPORT for a specific Lambda execution\"\"\"\n",
        "    execution_events = []\n",
        "    start_found = False\n",
        "    \n",
        "    for event in all_events:\n",
        "        message = event['message']\n",
        "        \n",
        "        # Look for START marker\n",
        "        if f\"START RequestId: {request_id}\" in message:\n",
        "            start_found = True\n",
        "            execution_events.append(event)\n",
        "            continue\n",
        "        \n",
        "        # If we found START, collect all logs until REPORT\n",
        "        if start_found:\n",
        "            execution_events.append(event)\n",
        "            \n",
        "            # Stop at REPORT marker (end of execution)\n",
        "            if f\"REPORT RequestId: {request_id}\" in message:\n",
        "                break\n",
        "    \n",
        "    return execution_events\n",
        "\n",
        "def wait_for_analyzer_logs(analyzer_function_name, request_id, timeout=60, check_interval=5):\n",
        "    \"\"\"Wait for analyzer agent to process the error using request ID\"\"\"\n",
        "    logs_client = boto3.client('logs')\n",
        "    log_group = f\"/aws/lambda/{analyzer_function_name}\"\n",
        "    \n",
        "    print(f\"‚è≥ Agent analyzing error (max {timeout}s)...\", end='', flush=True)\n",
        "    \n",
        "    start_time = time.time()\n",
        "    end_time = datetime.now()\n",
        "    \n",
        "    while time.time() - start_time < timeout:\n",
        "        try:\n",
        "            # Get recent log streams\n",
        "            streams_response = logs_client.describe_log_streams(\n",
        "                logGroupName=log_group,\n",
        "                orderBy='LastEventTime',\n",
        "                descending=True,\n",
        "                limit=5\n",
        "            )\n",
        "            \n",
        "            # Search in recent streams for our request ID\n",
        "            for stream in streams_response.get('logStreams', []):\n",
        "                stream_name = stream['logStreamName']\n",
        "                \n",
        "                events_response = logs_client.get_log_events(\n",
        "                    logGroupName=log_group,\n",
        "                    logStreamName=stream_name,\n",
        "                    limit=100,\n",
        "                    startFromHead=False\n",
        "                )\n",
        "                \n",
        "                # Check if this stream has our request ID with analysis complete\n",
        "                for event in events_response.get('events', []):\n",
        "                    if request_id in event['message'] and 'Agent Analysis Result' in event['message']:\n",
        "                        print(\" ‚úÖ\")\n",
        "                        return True\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        print(\".\", end='', flush=True)\n",
        "        time.sleep(check_interval)\n",
        "    \n",
        "    print(\" ‚ö†Ô∏è Timeout\")\n",
        "    return False\n",
        "\n",
        "def get_analyzer_logs(analyzer_function_name, business_request_id, minutes=2):\n",
        "    \"\"\"Fetch and display analyzer logs for specific business function execution\"\"\"\n",
        "    logs_client = boto3.client('logs')\n",
        "    log_group = f\"/aws/lambda/{analyzer_function_name}\"\n",
        "    \n",
        "    end_time = datetime.now()\n",
        "    start_time = end_time - timedelta(minutes=minutes)\n",
        "    \n",
        "    print(f\"\\nüìã Analyzer Logs (last {minutes} min):\")\n",
        "    print(\"=\" * 100)\n",
        "    \n",
        "    try:\n",
        "        # Get recent log streams\n",
        "        streams_response = logs_client.describe_log_streams(\n",
        "            logGroupName=log_group,\n",
        "            orderBy='LastEventTime',\n",
        "            descending=True,\n",
        "            limit=10\n",
        "        )\n",
        "        \n",
        "        found_analysis = False\n",
        "        \n",
        "        # Search through recent streams\n",
        "        for stream in streams_response.get('logStreams', []):\n",
        "            stream_name = stream['logStreamName']\n",
        "            \n",
        "            events_response = logs_client.get_log_events(\n",
        "                logGroupName=log_group,\n",
        "                logStreamName=stream_name,\n",
        "                startTime=int(start_time.timestamp() * 1000),\n",
        "                endTime=int(end_time.timestamp() * 1000),\n",
        "                limit=300  # Increased limit\n",
        "            )\n",
        "            \n",
        "            all_events = events_response.get('events', [])\n",
        "            \n",
        "            # Check if this stream contains our business request ID\n",
        "            has_our_request = any(business_request_id in e['message'] for e in all_events)\n",
        "            \n",
        "            if has_our_request:\n",
        "                found_analysis = True\n",
        "                \n",
        "                # Find the analyzer's request ID (START marker)\n",
        "                analyzer_request_id = None\n",
        "                for event in all_events:\n",
        "                    if 'START RequestId:' in event['message']:\n",
        "                        analyzer_request_id = event['message'].split('START RequestId: ')[1].split()[0]\n",
        "                        break\n",
        "                \n",
        "                print(f\"\\nüîç Found analysis for business request {business_request_id}\")\n",
        "                print(f\"   Analyzer execution: {analyzer_request_id}\")\n",
        "                print(f\"   Log stream: {stream_name}\\n\")\n",
        "                \n",
        "                # Extract full execution logs using the analyzer's request ID\n",
        "                if analyzer_request_id:\n",
        "                    execution_logs = extract_execution_logs(all_events, analyzer_request_id)\n",
        "                else:\n",
        "                    # Fallback: use all events if we can't find request ID\n",
        "                    execution_logs = all_events\n",
        "                \n",
        "                # Display ALL logs from this execution\n",
        "                for event in execution_logs:\n",
        "                    ts = datetime.fromtimestamp(event['timestamp'] / 1000)\n",
        "                    msg = event['message'].strip()\n",
        "                    \n",
        "                    # Highlight important messages\n",
        "                    if any(m in msg for m in ['ü§ñ', 'üìä', 'Root Cause', 'Confidence', 'Agent Analysis Result']):\n",
        "                        print(f\"\\n{'='*100}\")\n",
        "                        print(f\"[{ts.strftime('%H:%M:%S')}] {msg}\")\n",
        "                        print(f\"{'='*100}\\n\")\n",
        "                    elif 'Tool #' in msg or 'fetch_' in msg or 'search_' in msg:\n",
        "                        print(f\"  ‚Üí [{ts.strftime('%H:%M:%S')}] {msg}\")\n",
        "                    elif 'START RequestId' in msg or 'END RequestId' in msg or 'REPORT RequestId' in msg:\n",
        "                        print(f\"[{ts.strftime('%H:%M:%S')}] {msg}\")\n",
        "                    else:\n",
        "                        # Show all other logs too\n",
        "                        print(f\"[{ts.strftime('%H:%M:%S')}] {msg}\")\n",
        "                \n",
        "                break  # Found our analysis, stop searching\n",
        "        \n",
        "        if not found_analysis:\n",
        "            print(f\"‚ö†Ô∏è No analysis found for request ID {business_request_id}\")\n",
        "            print(f\"   The analyzer may still be processing or the request ID may be incorrect.\")\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test with Different Scenarios\n",
        "\n",
        "**üí° Tip:** If log output appears truncated:\n",
        "- Click on the output area\n",
        "- Right-click and select \"Enable Scrolling for Outputs\"\n",
        "- Or double-click the output to expand it fully"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 1: Missing Email Field (KeyError)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 1: Missing Email Field\n",
        "test_payload_1 = {\n",
        "    \"user_data\": {\n",
        "        \"profile\": {\"name\": \"John Doe\"},\n",
        "        \"age\": 30\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"üß™ Test 1: Missing Email (KeyError)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "response = lambda_client.invoke(\n",
        "    FunctionName=business_function_name,\n",
        "    InvocationType='RequestResponse',\n",
        "    Payload=json.dumps(test_payload_1)\n",
        ")\n",
        "\n",
        "request_id = response['ResponseMetadata']['RequestId']\n",
        "print(f\"‚úÖ Invoked - Request ID: {request_id}\")\n",
        "\n",
        "# Print Lambda response\n",
        "response_payload = json.loads(response['Payload'].read())\n",
        "print(f\"\\nüì§ Lambda Response:\")\n",
        "print(json.dumps(response_payload, indent=2))\n",
        "\n",
        "wait_for_analyzer_logs(analyzer_function_name, request_id)\n",
        "get_analyzer_logs(analyzer_function_name, request_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 2: Null Email (AttributeError)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 2: Null Email Value\n",
        "test_payload_2 = {\n",
        "    \"user_data\": {\n",
        "        \"email\": None,\n",
        "        \"profile\": {\"name\": \"Jane Smith\"},\n",
        "        \"age\": 25\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\n\\nüß™ Test 2: Null Email (AttributeError)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "response = lambda_client.invoke(\n",
        "    FunctionName=business_function_name,\n",
        "    InvocationType='RequestResponse',\n",
        "    Payload=json.dumps(test_payload_2)\n",
        ")\n",
        "\n",
        "request_id = response['ResponseMetadata']['RequestId']\n",
        "print(f\"‚úÖ Invoked - Request ID: {request_id}\")\n",
        "\n",
        "# Print Lambda response\n",
        "response_payload = json.loads(response['Payload'].read())\n",
        "print(f\"\\nüì§ Lambda Response:\")\n",
        "print(json.dumps(response_payload, indent=2))\n",
        "\n",
        "wait_for_analyzer_logs(analyzer_function_name, request_id)\n",
        "get_analyzer_logs(analyzer_function_name, request_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Enable Claude Sonnet 4 for Enhanced Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enable Claude Sonnet 4 with Interleaved Thinking\n",
        "print(\"\\n\\nüîß Enabling Claude Sonnet 4\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    config = lambda_client.get_function_configuration(FunctionName=analyzer_function_name)\n",
        "    env_vars = config.get('Environment', {}).get('Variables', {})\n",
        "    env_vars['USE_SONNET_4'] = 'true'\n",
        "    \n",
        "    lambda_client.update_function_configuration(\n",
        "        FunctionName=analyzer_function_name,\n",
        "        Environment={'Variables': env_vars}\n",
        "    )\n",
        "    \n",
        "    print(\"‚úÖ Updated USE_SONNET_4=true\")\n",
        "    print(\"‚è≥ Waiting for update...\", end='', flush=True)\n",
        "    \n",
        "    waiter = lambda_client.get_waiter('function_updated')\n",
        "    waiter.wait(FunctionName=analyzer_function_name)\n",
        "    \n",
        "    print(\" Done!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 3: Division by Zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 3: Division by Zero (with Sonnet 4)\n",
        "test_payload_3 = {\n",
        "    \"user_data\": {\n",
        "        \"email\": \"asif.mithawala@example.com\",\n",
        "        \"profile\": {\"name\": \"Asif Mithawala\"},\n",
        "        \"age\": 0,\n",
        "        \"initial_deposit\": 1000,\n",
        "        \"registration_date\": \"2024-01-15\",\n",
        "        \"settings\": {\"preferences\": {\"notifications\": [\"email\"]}}\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\n\\nüß™ Test 3: Zero Age / Division by Zero (Sonnet 4)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "response = lambda_client.invoke(\n",
        "    FunctionName=business_function_name,\n",
        "    InvocationType='RequestResponse',\n",
        "    Payload=json.dumps(test_payload_3)\n",
        ")\n",
        "\n",
        "request_id = response['ResponseMetadata']['RequestId']\n",
        "print(f\"‚úÖ Invoked - Request ID: {request_id}\")\n",
        "\n",
        "# Print Lambda response\n",
        "response_payload = json.loads(response['Payload'].read())\n",
        "print(f\"\\nüì§ Lambda Response:\")\n",
        "print(json.dumps(response_payload, indent=2))\n",
        "\n",
        "wait_for_analyzer_logs(analyzer_function_name, request_id)\n",
        "get_analyzer_logs(analyzer_function_name, request_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View DynamoDB Analysis Results\n",
        "\n",
        "Let's query the DynamoDB table to see all the stored analysis results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from decimal import Decimal\n",
        "from IPython.display import display\n",
        "\n",
        "dynamodb = boto3.resource('dynamodb')\n",
        "\n",
        "# Find our analysis table\n",
        "tables = list(dynamodb.tables.all())\n",
        "analysis_table = None\n",
        "\n",
        "for table in tables:\n",
        "    if 'LambdaErrorAnalysis-error-analysis' in table.name:\n",
        "        analysis_table = table\n",
        "        break\n",
        "\n",
        "if analysis_table:\n",
        "    # Scan table with pagination\n",
        "    response = analysis_table.scan()\n",
        "    items = response['Items']\n",
        "    \n",
        "    while 'LastEvaluatedKey' in response:\n",
        "        response = analysis_table.scan(ExclusiveStartKey=response['LastEvaluatedKey'])\n",
        "        items.extend(response['Items'])\n",
        "    \n",
        "    # Convert Decimal to float\n",
        "    def decimal_to_float(obj):\n",
        "        if isinstance(obj, list):\n",
        "            return [decimal_to_float(i) for i in obj]\n",
        "        elif isinstance(obj, dict):\n",
        "            return {k: decimal_to_float(v) for k, v in obj.items()}\n",
        "        elif isinstance(obj, Decimal):\n",
        "            return float(obj)\n",
        "        return obj\n",
        "    \n",
        "    items = [decimal_to_float(item) for item in items]\n",
        "    \n",
        "    if items:\n",
        "        df = pd.DataFrame(items)\n",
        "        \n",
        "        # Sort by timestamp\n",
        "        if 'timestamp' in df.columns:\n",
        "            df = df.sort_values('timestamp', ascending=False)\n",
        "        \n",
        "        # Select columns\n",
        "        columns = ['error_id', 'timestamp', 'function_name', 'agent_analysis', 'analysis_duration_mm_ss']\n",
        "        df = df[[col for col in columns if col in df.columns]]\n",
        "        \n",
        "        # Truncate error_id only\n",
        "        if 'error_id' in df.columns:\n",
        "            df['error_id'] = df['error_id'].str[:35]\n",
        "        \n",
        "        # Set pandas display options to show full text\n",
        "        pd.set_option('display.max_colwidth', None)\n",
        "        \n",
        "        display(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "You've successfully:\n",
        "\n",
        "1. ‚úÖ Deployed the Lambda Error Analysis system\n",
        "2. ‚úÖ Tested with 3 different failure scenarios\n",
        "3. ‚úÖ Viewed AI-powered error analysis in CloudWatch logs\n",
        "4. ‚úÖ Queried analysis results from DynamoDB\n",
        "\n",
        "### Key Takeaways:\n",
        "\n",
        "- The `@error_capture` decorator automatically captures failures\n",
        "- EventBridge routes errors to the AI analyzer\n",
        "- The Strands Agent uses 3 tools to gather comprehensive context\n",
        "- Claude Sonnet provides intelligent analysis with confidence scoring\n",
        "- All analysis is stored in DynamoDB for historical tracking\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "1. **Add to your Lambda functions** - Copy the decorator to your own functions\n",
        "2. **Customize the agent** - Modify system prompts for your use case\n",
        "3. **Expand knowledge base** - Add your organization's error patterns\n",
        "4. **Monitor trends** - Use DynamoDB data to identify recurring issues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleanup\n",
        "\n",
        "When you're done testing, clean up the resources:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Destroy the CDK stack\n",
        "!npx cdk destroy --force"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
